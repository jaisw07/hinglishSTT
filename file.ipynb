{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947e03b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Hi, mera naam shri jaisvaal hai aur yah audio main record kar raha hoon to warm up the whisper STT app which we are trying to demo and give it an input of both hindi and english languages taaki yah sahi se initialize ho jaata hai and our warm up text, our warm up audio sorry, contains both languages, so this is it.', 'chunks': [{'timestamp': (0.0, 22.68), 'text': 'Hi, mera naam shri jaisvaal hai aur yah audio main record kar raha hoon to warm up the whisper STT app which we are trying to demo and give it an input of both hindi and english languages taaki yah sahi se initialize ho jaata hai and our warm up text, our warm up audio sorry, contains both languages, so this is it.'}]}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import ffmpeg\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "# from datasets import load_dataset\n",
    "\n",
    "# Set device (GPU if available, otherwise CPU) and precision\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "# Specify the pre-trained model ID\n",
    "model_id = \"Oriserve/Whisper-Hindi2Hinglish-Apex\"\n",
    "\n",
    "# Load the speech-to-text model with specified configurations\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch_dtype,        # Use appropriate precision (float16 for GPU, float32 for CPU)\n",
    "    low_cpu_mem_usage=True,         # Optimize memory usage during loading\n",
    "    use_safetensors=True            # Use safetensors format for better security\n",
    ")\n",
    "model.to(device)                    # Move model to specified device\n",
    "\n",
    "# Load the processor for audio preprocessing and tokenization\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "# Create speech recognition pipeline\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    return_timestamps=True,\n",
    "    device=device,\n",
    "    generate_kwargs={\n",
    "        \"task\": \"transcribe\",       # Set task to transcription\n",
    "        \"language\": \"en\"            # Specify English language\n",
    "    }\n",
    ")\n",
    "\n",
    "# Process audio file and print transcription\n",
    "sample = r\"C:\\Users\\SHREY\\Desktop\\SpeechToText\\hinglish_stt\\warmup.mp3\"             # Input audio file path\n",
    "result = pipe(sample)               # Run inference\n",
    "print(result[\"text\"])               # Print transcribed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1b4185",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hi, mera naam shri jaisvaal hai aur yah audio main record kar raha hoon to warm up the whisper STT app which we are trying to demo and give it an input of both hindi and english languages taaki yah sahi se initialize ho jaata hai and our warm up text, our warm up audio sorry, contains both languages, so this is it.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import stt\n",
    "stt.runTranscription(r\"C:\\Users\\SHREY\\Desktop\\SpeechToText\\hinglish_stt\\warmup.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6616d492",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper_stt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
